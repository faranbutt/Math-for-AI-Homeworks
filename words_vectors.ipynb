{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAmUD1eZHryf"
      },
      "source": [
        "# **Word vectors**\n",
        "\n",
        "\n",
        "In the previous exercise we observed that colors that we think of as similar are 'closer' to each other in RGB vector space. Is it possible to create a vector space for all English words that has this same 'closer in space is closer in meaning' property?\n",
        "\n",
        "The answer is yes! Luckily, you don't need to create those vectors from scratch. Many researchers have made downloadable databases of pre-trained vectors. One such project is [Stanford's Global Vectors for Word Representation (GloVe)](https://nlp.stanford.edu/projects/glove/).\n",
        "\n",
        "These $300$-dimensional vectors are included with $\\texttt{spaCy}$, and they're the vectors we'll be using in this exercise.\n",
        "\n",
        "![cosine similarity: picture](https://d33wubrfki0l68.cloudfront.net/d2742976a92aa4d6c39f19c747ec5f56ed1cec30/3803f/images/guide-to-word-vectors-with-gensim-and-keras_files/word2vec-king-queen-vectors.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymHr8XZIHsML",
        "collapsed": true,
        "outputId": "5c5175db-3fed-4596-a4b5-26188c1dc823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The following will download the language model.\n",
        "# Resart the runtime (Runtime -> Restart runtime) after running this cell\n",
        "# (and don't run it for the second time).\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb7yqHuGJ6e5"
      },
      "source": [
        "Let's load the model now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-8rsSkSBU8C"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNf5FAkm3Ljj"
      },
      "source": [
        "## **Word vectors: the first glance**\n",
        "\n",
        "You can see the vector of any word in $\\texttt{spaCy}$' s vocabulary using the $\\texttt{vector}$ attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx-IzWxQAgNN",
        "outputId": "b0761acb-3e61-46a4-9032-518db508f9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# A 300-dimensional vector\n",
        "len(nlp('dog').vector)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8UP3QrxKZPG",
        "outputId": "6df12302-06c6-411e-d029-bd76fb5b92e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp('dog').vector"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.2330e+00,  4.2963e+00, -7.9738e+00, -1.0121e+01,  1.8207e+00,\n",
              "        1.4098e+00, -4.5180e+00, -5.2261e+00, -2.9157e-01,  9.5234e-01,\n",
              "        6.9880e+00,  5.0637e+00, -5.5726e-03,  3.3395e+00,  6.4596e+00,\n",
              "       -6.3742e+00,  3.9045e-02, -3.9855e+00,  1.2085e+00, -1.3186e+00,\n",
              "       -4.8886e+00,  3.7066e+00, -2.8281e+00, -3.5447e+00,  7.6888e-01,\n",
              "        1.5016e+00, -4.3632e+00,  8.6480e+00, -5.9286e+00, -1.3055e+00,\n",
              "        8.3870e-01,  9.0137e-01, -1.7843e+00, -1.0148e+00,  2.7300e+00,\n",
              "       -6.9039e+00,  8.0413e-01,  7.4880e+00,  6.1078e+00, -4.2130e+00,\n",
              "       -1.5384e-01, -5.4995e+00,  1.0896e+01,  3.9278e+00, -1.3601e-01,\n",
              "        7.7732e-02,  3.2218e+00, -5.8777e+00,  6.1359e-01, -2.4287e+00,\n",
              "        6.2820e+00,  1.3461e+01,  4.3236e+00,  2.4266e+00, -2.6512e+00,\n",
              "        1.1577e+00,  5.0848e+00, -1.7058e+00,  3.3824e+00,  3.2850e+00,\n",
              "        1.0969e+00, -8.3711e+00, -1.5554e+00,  2.0296e+00, -2.6796e+00,\n",
              "       -6.9195e+00, -2.3386e+00, -1.9916e+00, -3.0450e+00,  2.4890e+00,\n",
              "        7.3247e+00,  1.3364e+00,  2.3828e-01,  8.4388e-02,  3.1480e+00,\n",
              "       -1.1128e+00, -3.5598e+00, -1.2115e-01, -2.0357e+00, -3.2731e+00,\n",
              "       -7.7205e+00,  4.0948e+00, -2.0732e+00,  2.0833e+00, -2.2803e+00,\n",
              "       -4.9850e+00,  9.7667e+00,  6.1779e+00, -1.0352e+01, -2.2268e+00,\n",
              "        2.5765e+00, -5.7440e+00,  5.5564e+00, -5.2735e+00,  3.0004e+00,\n",
              "       -4.2512e+00, -1.5682e+00,  2.2698e+00,  1.0491e+00, -9.0486e+00,\n",
              "        4.2936e+00,  1.8709e+00,  5.1985e+00, -1.3153e+00,  6.5224e+00,\n",
              "        4.0113e-01, -1.2583e+01,  3.6534e+00, -2.0961e+00,  1.0022e+00,\n",
              "       -1.7873e+00, -4.2555e+00,  7.7471e+00,  1.0173e+00,  3.1626e+00,\n",
              "        2.3558e+00,  3.3589e-01, -4.4178e+00,  5.0584e+00, -2.4118e+00,\n",
              "       -2.7445e+00,  3.4170e+00, -1.1574e+01, -2.6568e+00, -3.6933e+00,\n",
              "       -2.0398e+00,  5.0976e+00,  6.5249e+00,  3.3573e+00,  9.5334e-01,\n",
              "       -9.4430e-01, -9.4395e+00,  2.7867e+00, -1.7549e+00,  1.7287e+00,\n",
              "        3.4942e+00, -1.6883e+00, -3.5771e+00, -1.9013e+00,  2.2239e+00,\n",
              "       -5.4335e+00, -6.5724e+00, -6.7228e-01, -1.9748e+00, -3.1080e+00,\n",
              "       -1.8570e+00,  9.9496e-01,  8.9135e-01, -4.4254e+00,  3.3125e-01,\n",
              "        5.8815e+00,  1.9384e+00,  5.7294e-01, -2.8830e+00,  3.8087e+00,\n",
              "       -1.3095e+00,  5.9208e+00,  3.3620e+00,  3.3571e+00, -3.8807e-01,\n",
              "        9.0022e-01, -5.5742e+00, -4.2939e+00,  1.4992e+00, -4.7080e+00,\n",
              "       -2.9402e+00, -1.2259e+00,  3.0980e-01,  1.8858e+00, -1.9867e+00,\n",
              "       -2.3554e-01, -5.4535e-01, -2.1387e-01,  2.4797e+00,  5.9710e+00,\n",
              "       -7.1249e+00,  1.6257e+00, -1.5241e+00,  7.5974e-01,  1.4312e+00,\n",
              "        2.3641e+00, -3.5566e+00,  9.2066e-01,  4.4934e-01, -1.3233e+00,\n",
              "        3.1733e+00, -4.7059e+00, -1.2090e+01, -3.9241e-01, -6.8457e-01,\n",
              "       -3.6789e+00,  6.6279e+00, -2.9937e+00, -3.8361e+00,  1.3868e+00,\n",
              "       -4.9002e+00, -2.4299e+00,  6.4312e+00,  2.5056e+00, -4.5080e+00,\n",
              "       -5.1278e+00, -1.5585e+00, -3.0226e+00, -8.6811e-01, -1.1538e+00,\n",
              "       -1.0022e+00, -9.1651e-01, -4.7810e-01, -1.6084e+00, -2.7307e+00,\n",
              "        3.7080e+00,  7.7423e-01, -1.1085e+00, -6.8755e-01, -8.2901e+00,\n",
              "        3.2405e+00, -1.6108e-01, -6.2837e-01, -5.5960e+00, -4.4865e+00,\n",
              "        4.0115e-01, -3.7063e+00, -2.1704e+00,  4.0789e+00, -1.7973e+00,\n",
              "        8.9538e+00,  8.9421e-01, -4.8128e+00,  4.5367e+00, -3.2579e-01,\n",
              "       -5.2344e+00, -3.9766e+00, -2.1979e+00,  3.5699e+00,  1.4982e+00,\n",
              "        6.0972e+00, -1.9704e+00,  4.6522e+00, -3.7734e-01,  3.9101e-02,\n",
              "        2.5361e+00, -1.8096e+00,  8.7035e+00, -8.6372e+00, -3.5257e+00,\n",
              "        3.1034e+00,  3.2635e+00,  4.5437e+00, -5.7290e+00, -2.9141e-01,\n",
              "       -2.0011e+00,  8.5328e+00, -4.5064e+00, -4.8276e+00, -1.1786e+01,\n",
              "        3.5607e-01, -5.7115e+00,  6.3122e+00, -3.6650e+00,  3.3597e-01,\n",
              "        2.5017e+00, -3.5025e+00, -3.7891e+00, -3.1343e+00, -1.4429e+00,\n",
              "       -6.9119e+00, -2.6114e+00, -5.9757e-01,  3.7847e-01,  6.3187e+00,\n",
              "        2.8965e+00, -2.5397e+00,  1.8022e+00,  3.5486e+00,  4.4721e+00,\n",
              "       -4.8481e+00, -3.6252e+00,  4.0969e+00, -2.0081e+00, -2.0122e-01,\n",
              "        2.5244e+00, -6.8817e-01,  6.7184e-01, -7.0466e+00,  1.6641e+00,\n",
              "       -2.2308e+00, -3.8960e+00,  6.1320e+00, -8.0335e+00, -1.7130e+00,\n",
              "        2.5688e+00, -5.2547e+00,  6.9845e+00,  2.7835e-01, -6.4554e+00,\n",
              "       -2.1327e+00, -5.6515e+00,  1.1174e+01, -8.0568e+00,  5.7985e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHWCqKcl55TY"
      },
      "source": [
        "## **Cosine similarity**\n",
        "\n",
        "**Cosine similarity** is a common way of assessing similarity between words in NLP. It is essentially defined as the cosine of the angle between the vectors representing the words of interest.\n",
        "\n",
        "Recall that the angle $\\phi$ between two non-zero vectors $u$ and $v$ can be computed as follows:\n",
        "\n",
        "$cos(\\phi) = \\frac{(u,v)}{||u||\\cdot||v||}$\n",
        "\n",
        "![](https://miro.medium.com/max/1394/1*_Bf9goaALQrS_0XkBozEiQ.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoi6FvPgMWid"
      },
      "source": [
        "Define a function computing cosine similarity between two vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpJS01dmvGbe"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine(v1, v2):\n",
        "  # Your code here\n",
        "  cs = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "  return cs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEwtAXJRMc-s"
      },
      "source": [
        "Test your function by computing similarities of some random pairs of words, e.g. $dog$ and $puppy$ vs. $dog$ and $kitten$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RBooDbGvYOG",
        "outputId": "62c9cf9b-1777-4d6b-a894-825936bb10bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Your code here\n",
        "v1 = nlp('dog').vector\n",
        "v2 = nlp('puppy').vector\n",
        "cos_sim = cosine(v1, v2)\n",
        "cos_sim"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81076676"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgHDwfx8Mu66"
      },
      "source": [
        "## **Loading the text**\n",
        "\n",
        "Let's load the full text of *Alice in Wonderland*. It will serve us as a corpus of English words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am8NoIl2zMXi"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Alice in Wonderland\n",
        "response = requests.get('https://www.gutenberg.org/files/11/11-0.txt')\n",
        "\n",
        "# If you prefer Dracula, load this instead:\n",
        "#response = requests.get('https://www.gutenberg.org/cache/epub/345/pg345.txt')\n",
        "\n",
        "# Extracting separate words from the text\n",
        "doc = nlp(response.text)\n",
        "tokens = list(set([w.text for w in doc if w.is_alpha]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAwABf4nNNR3"
      },
      "source": [
        "Check out the content of $\\texttt{tokens}$ now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4B4FRR6NRzx",
        "outputId": "dac12a83-4ebd-44c1-fc38-a2d19f7ec8cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ignorant',\n",
              " 'into',\n",
              " 'fellow',\n",
              " 'exclaimed',\n",
              " 'circumstances',\n",
              " 'It',\n",
              " 'blue',\n",
              " 'eager',\n",
              " 'ran',\n",
              " 'eleventh',\n",
              " 'flustered',\n",
              " 'ugly',\n",
              " 'flying',\n",
              " 'New',\n",
              " 'whole',\n",
              " 'uncivil',\n",
              " 'merrily',\n",
              " 'belong',\n",
              " 'soup',\n",
              " 'Therefore',\n",
              " 'cherry',\n",
              " 'shake',\n",
              " 'wink',\n",
              " 'herself',\n",
              " 'bend',\n",
              " 'END',\n",
              " 'flock',\n",
              " 'fountains',\n",
              " 'length',\n",
              " 'hollow',\n",
              " 'nurse',\n",
              " 'ears',\n",
              " 'noises',\n",
              " 'year',\n",
              " 'verdict',\n",
              " 'considering',\n",
              " 'again',\n",
              " 'Hardly',\n",
              " 'afford',\n",
              " 'reaching',\n",
              " 'boy',\n",
              " 'camomile',\n",
              " 'afore',\n",
              " 'sign',\n",
              " 'venture',\n",
              " 'Stop',\n",
              " 'common',\n",
              " 'rapidly',\n",
              " 'See',\n",
              " 'singers',\n",
              " 'uncommonly',\n",
              " 'pardon',\n",
              " 'skirt',\n",
              " 'just',\n",
              " 'telescopes',\n",
              " 'turtles',\n",
              " 'thanked',\n",
              " 'dozing',\n",
              " 'couples',\n",
              " 'across',\n",
              " 'shouted',\n",
              " 'THE',\n",
              " 'crust',\n",
              " 'Caucus',\n",
              " 'labelled',\n",
              " 'patiently',\n",
              " 'paused',\n",
              " 'stingy',\n",
              " 'age',\n",
              " 'morals',\n",
              " 'live',\n",
              " 'Table',\n",
              " 'sorry',\n",
              " 'speech',\n",
              " 'remembering',\n",
              " 'older',\n",
              " 'rumbling',\n",
              " 'bee',\n",
              " 'remain',\n",
              " 'word',\n",
              " 'pepper',\n",
              " 'wearily',\n",
              " 'calmly',\n",
              " 'added',\n",
              " 'scaly',\n",
              " 'obliged',\n",
              " 'wherever',\n",
              " 'howling',\n",
              " 'write',\n",
              " 'really',\n",
              " 'planning',\n",
              " 'pause',\n",
              " 'ear',\n",
              " 'kept',\n",
              " 'authority',\n",
              " 'absurd',\n",
              " 'Shall',\n",
              " 'angry',\n",
              " 'hung',\n",
              " 'dressed',\n",
              " 'usurpation',\n",
              " 'replied',\n",
              " 'what',\n",
              " 'same',\n",
              " 'confused',\n",
              " 'relieved',\n",
              " 'how',\n",
              " 'grave',\n",
              " 'plates',\n",
              " 'stole',\n",
              " 'Imagine',\n",
              " 'grumbled',\n",
              " 'fan',\n",
              " 'that',\n",
              " 'nor',\n",
              " 'ordered',\n",
              " 'also',\n",
              " 'hope',\n",
              " 'hopeless',\n",
              " 'bite',\n",
              " 'Bill',\n",
              " 'left',\n",
              " 'begins',\n",
              " 'Mad',\n",
              " 'family',\n",
              " 'alas',\n",
              " 'wrong',\n",
              " 'law',\n",
              " 'upstairs',\n",
              " 'laid',\n",
              " 'certainly',\n",
              " 'suet',\n",
              " 'crawled',\n",
              " 'by',\n",
              " 'branches',\n",
              " 'reminding',\n",
              " 'such',\n",
              " 'dig',\n",
              " 'belongs',\n",
              " 'cold',\n",
              " 'follows',\n",
              " 'wore',\n",
              " 'lap',\n",
              " 'Story',\n",
              " 'stupidest',\n",
              " 'poured',\n",
              " 'drawing',\n",
              " 'kills',\n",
              " 'vegetable',\n",
              " 'disappeared',\n",
              " 'shock',\n",
              " 'heard',\n",
              " 'The',\n",
              " 'sentence',\n",
              " 'ridge',\n",
              " 'humbly',\n",
              " 'teacups',\n",
              " 'climb',\n",
              " 'lay',\n",
              " 'farmer',\n",
              " 'paper',\n",
              " 'arguments',\n",
              " 'rude',\n",
              " 'on',\n",
              " 'While',\n",
              " 'However',\n",
              " 'girl',\n",
              " 'vague',\n",
              " 'learned',\n",
              " 'clasped',\n",
              " 'wept',\n",
              " 'would',\n",
              " 'burn',\n",
              " 'queer',\n",
              " 'joined',\n",
              " 'closed',\n",
              " 'Nobody',\n",
              " 'but',\n",
              " 'state',\n",
              " 'living',\n",
              " 'sounded',\n",
              " 'practice',\n",
              " 'solemnly',\n",
              " 'teaching',\n",
              " 'interrupted',\n",
              " 'sometimes',\n",
              " 'piece',\n",
              " 'slates',\n",
              " 'delay',\n",
              " 'uncorked',\n",
              " 'natural',\n",
              " 'chance',\n",
              " 'tried',\n",
              " 'crowded',\n",
              " 'line',\n",
              " 'doing',\n",
              " 'gloves',\n",
              " 'strange',\n",
              " 'arranged',\n",
              " 'considered',\n",
              " 'wondered',\n",
              " 'Queen',\n",
              " 'quickly',\n",
              " 'another',\n",
              " 'sentenced',\n",
              " 'somebody',\n",
              " 'seemed',\n",
              " 'subdued',\n",
              " 'capering',\n",
              " 'tremulous',\n",
              " 'believed',\n",
              " 'squeeze',\n",
              " 'Before',\n",
              " 'fits',\n",
              " 'knee',\n",
              " 'counting',\n",
              " 'entangled',\n",
              " 'promise',\n",
              " 'giving',\n",
              " 'sulky',\n",
              " 'leaning',\n",
              " 'next',\n",
              " 'explained',\n",
              " 'White',\n",
              " 'grunted',\n",
              " 'scream',\n",
              " 'Uglification',\n",
              " 'arches',\n",
              " 'finishing',\n",
              " 'swallow',\n",
              " 'race',\n",
              " 'undo',\n",
              " 'here',\n",
              " 'thought',\n",
              " 'curtsey',\n",
              " 'surprised',\n",
              " 'flame',\n",
              " 'trembled',\n",
              " 'Morcar',\n",
              " 'stupid',\n",
              " 'party',\n",
              " 'carefully',\n",
              " 'rightly',\n",
              " 'land',\n",
              " 'elbows',\n",
              " 'dears',\n",
              " 'important',\n",
              " 'Five',\n",
              " 'direction',\n",
              " 'March',\n",
              " 'ornamented',\n",
              " 'In',\n",
              " 'somersault',\n",
              " 'smiled',\n",
              " 'accustomed',\n",
              " 'sob',\n",
              " 'spoon',\n",
              " 'below',\n",
              " 'catching',\n",
              " 'apple',\n",
              " 'place',\n",
              " 'uneasy',\n",
              " 'beg',\n",
              " 'folded',\n",
              " 'brushing',\n",
              " 'does',\n",
              " 'waving',\n",
              " 'good',\n",
              " 'fell',\n",
              " 'cry',\n",
              " 'bear',\n",
              " 'sharing',\n",
              " 'sell',\n",
              " 'beast',\n",
              " 'English',\n",
              " 'foolish',\n",
              " 'vote',\n",
              " 'quarrelled',\n",
              " 'PROJECT',\n",
              " 'bill',\n",
              " 'sorts',\n",
              " 'chanced',\n",
              " 'always',\n",
              " 'at',\n",
              " 'trampled',\n",
              " 'sobbed',\n",
              " 'he',\n",
              " 'attended',\n",
              " 'deepest',\n",
              " 'standing',\n",
              " 'flashed',\n",
              " 'shelves',\n",
              " 'Game',\n",
              " 'reading',\n",
              " 'beautifully',\n",
              " 'earth',\n",
              " 'beasts',\n",
              " 'stirring',\n",
              " 'pigeon',\n",
              " 'mark',\n",
              " 'terribly',\n",
              " 'French',\n",
              " 'chain',\n",
              " 'solid',\n",
              " 'shillings',\n",
              " 'looking',\n",
              " 'sat',\n",
              " 'red',\n",
              " 'upsetting',\n",
              " 'mile',\n",
              " 'violently',\n",
              " 'triumphantly',\n",
              " 'reasonable',\n",
              " 'Poor',\n",
              " 'livery',\n",
              " 'editions',\n",
              " 'furrows',\n",
              " 'seeing',\n",
              " 'Tea',\n",
              " 'anything',\n",
              " 'takes',\n",
              " 'bells',\n",
              " 'rearing',\n",
              " 'IX',\n",
              " 'immediately',\n",
              " 'room',\n",
              " 'natured',\n",
              " 'among',\n",
              " 'calling',\n",
              " 'noticed',\n",
              " 'jury',\n",
              " 'proposal',\n",
              " 'delighted',\n",
              " 'held',\n",
              " 'footmen',\n",
              " 'provoking',\n",
              " 'Involved',\n",
              " 'bag',\n",
              " 'nowhere',\n",
              " 'diligently',\n",
              " 'acceptance',\n",
              " 'air',\n",
              " 'dates',\n",
              " 'interesting',\n",
              " 'shepherd',\n",
              " 'beginning',\n",
              " 'downwards',\n",
              " 'neither',\n",
              " 'ashamed',\n",
              " 'passed',\n",
              " 'advisable',\n",
              " 'chains',\n",
              " 'begun',\n",
              " 'tells',\n",
              " 'dreadful',\n",
              " 'farm',\n",
              " 'anxious',\n",
              " 'Let',\n",
              " 'history',\n",
              " 'dipped',\n",
              " 'birthday',\n",
              " 'lazily',\n",
              " 'lazy',\n",
              " 'spirited',\n",
              " 'bough',\n",
              " 'stairs',\n",
              " 'walked',\n",
              " 'given',\n",
              " 'few',\n",
              " 'dive',\n",
              " 'sixpence',\n",
              " 'Mouse',\n",
              " 'croqueting',\n",
              " 'stay',\n",
              " 'dunce',\n",
              " 'grinned',\n",
              " 'carrier',\n",
              " 'grew',\n",
              " 'grey',\n",
              " 'words',\n",
              " 'precious',\n",
              " 'bursting',\n",
              " 'purring',\n",
              " 'IN',\n",
              " 'examining',\n",
              " 'rather',\n",
              " 'doth',\n",
              " 'handed',\n",
              " 'kiss',\n",
              " 'meanwhile',\n",
              " 'frightened',\n",
              " 'beautify',\n",
              " 'weak',\n",
              " 'opportunity',\n",
              " 'straight',\n",
              " 'Evidence',\n",
              " 'yours',\n",
              " 'pitied',\n",
              " 'teacup',\n",
              " 'worth',\n",
              " 'chief',\n",
              " 'truth',\n",
              " 'Pinch',\n",
              " 'oldest',\n",
              " 'creatures',\n",
              " 'waistcoat',\n",
              " 'harm',\n",
              " 'certain',\n",
              " 'my',\n",
              " 'hatters',\n",
              " 'affectionately',\n",
              " 'jar',\n",
              " 'desks',\n",
              " 'Always',\n",
              " 'set',\n",
              " 'serpents',\n",
              " 'forwards',\n",
              " 'distant',\n",
              " 'gained',\n",
              " 'stretching',\n",
              " 'wretched',\n",
              " 'difficulty',\n",
              " 'pleasing',\n",
              " 'pour',\n",
              " 'highest',\n",
              " 'shrieked',\n",
              " 'wriggling',\n",
              " 'waters',\n",
              " 'stoop',\n",
              " 'unlocking',\n",
              " 'they',\n",
              " 'against',\n",
              " 'plan',\n",
              " 'possibly',\n",
              " 'barking',\n",
              " 'keeping',\n",
              " 'recovered',\n",
              " 'grown',\n",
              " 'busy',\n",
              " 'settle',\n",
              " 'say',\n",
              " 'raven',\n",
              " 'faintly',\n",
              " 'leant',\n",
              " 'kettle',\n",
              " 'inquisitively',\n",
              " 'me',\n",
              " 'right',\n",
              " 'undoing',\n",
              " 'inclined',\n",
              " 'fairly',\n",
              " 'lonely',\n",
              " 'louder',\n",
              " 'things',\n",
              " 'fortunately',\n",
              " 'repeated',\n",
              " 'gallons',\n",
              " 'minded',\n",
              " 'silence',\n",
              " 'trying',\n",
              " 'Only',\n",
              " 'XII',\n",
              " 'choosing',\n",
              " 'doze',\n",
              " 'Edwin',\n",
              " 'WONDERLAND',\n",
              " 'usually',\n",
              " 'tails',\n",
              " 'beat',\n",
              " 'knelt',\n",
              " 'bit',\n",
              " 'managed',\n",
              " 'want',\n",
              " 'sand',\n",
              " 'disagree',\n",
              " 'dreamy',\n",
              " 'flavour',\n",
              " 'After',\n",
              " 'wow',\n",
              " 'wash',\n",
              " 'swimming',\n",
              " 'after',\n",
              " 'sky',\n",
              " 'trial',\n",
              " 'dogs',\n",
              " 'nonsense',\n",
              " 'ten',\n",
              " 'slate',\n",
              " 'distance',\n",
              " 'adventures',\n",
              " 'With',\n",
              " 'hundred',\n",
              " 'ink',\n",
              " 'within',\n",
              " 'centre',\n",
              " 'argument',\n",
              " 'past',\n",
              " 'somewhere',\n",
              " 'shrink',\n",
              " 'cartwheels',\n",
              " 'reply',\n",
              " 'shining',\n",
              " 'regular',\n",
              " 'indeed',\n",
              " 'honest',\n",
              " 'sorrow',\n",
              " 'Fender',\n",
              " 'immense',\n",
              " 'singing',\n",
              " 'Come',\n",
              " 'imagine',\n",
              " 'three',\n",
              " 'beheading',\n",
              " 'animals',\n",
              " 'agree',\n",
              " 'promised',\n",
              " 'These',\n",
              " 'fit',\n",
              " 'childhood',\n",
              " 'straightened',\n",
              " 'escape',\n",
              " 'underneath',\n",
              " 'book',\n",
              " 'locks',\n",
              " 'knew',\n",
              " 'She',\n",
              " 'explain',\n",
              " 'hide',\n",
              " 'hurrying',\n",
              " 'about',\n",
              " 'VII',\n",
              " 'marched',\n",
              " 'trotting',\n",
              " 'comfort',\n",
              " 'repeat',\n",
              " 'accident',\n",
              " 'delight',\n",
              " 'growing',\n",
              " 'meet',\n",
              " 'wider',\n",
              " 'denying',\n",
              " 'William',\n",
              " 'court',\n",
              " 'pale',\n",
              " 'bristling',\n",
              " 'thing',\n",
              " 'fixed',\n",
              " 'wife',\n",
              " 'saucepans',\n",
              " 'throw',\n",
              " 'make',\n",
              " 'thoughtfully',\n",
              " 'accidentally',\n",
              " 'drew',\n",
              " 'Lacie',\n",
              " 'enormous',\n",
              " 'tricks',\n",
              " 'dark',\n",
              " 'temper',\n",
              " 'wonderful',\n",
              " 'which',\n",
              " 'memory',\n",
              " 'Exactly',\n",
              " 'search',\n",
              " 'ring',\n",
              " 'alternately',\n",
              " 'content',\n",
              " 'lamps',\n",
              " 'furrow',\n",
              " 'morsel',\n",
              " 'ridges',\n",
              " 'teapot',\n",
              " 'tired',\n",
              " 'Stole',\n",
              " 'moved',\n",
              " 'dreamed',\n",
              " 'were',\n",
              " 'till',\n",
              " 'II',\n",
              " 'peeped',\n",
              " 'paws',\n",
              " 'adjourn',\n",
              " 'Yet',\n",
              " 'axes',\n",
              " 'cattle',\n",
              " 'melancholy',\n",
              " 'blacking',\n",
              " 'faster',\n",
              " 'advice',\n",
              " 'exact',\n",
              " 'squeaked',\n",
              " 'usual',\n",
              " 'Because',\n",
              " 'are',\n",
              " 'claws',\n",
              " 'conversation',\n",
              " 'roast',\n",
              " 'dishes',\n",
              " 'carrying',\n",
              " 'toes',\n",
              " 'changes',\n",
              " 'refused',\n",
              " 'Never',\n",
              " 'riper',\n",
              " 'time',\n",
              " 'no',\n",
              " 'hedge',\n",
              " 'grand',\n",
              " 'howled',\n",
              " 'everything',\n",
              " 'reason',\n",
              " 'sleep',\n",
              " 'There',\n",
              " 'ordering',\n",
              " 'much',\n",
              " 'sight',\n",
              " 'thoughts',\n",
              " 'tongue',\n",
              " 'mallets',\n",
              " 'warning',\n",
              " 'loose',\n",
              " 'appear',\n",
              " 'happening',\n",
              " 'tasted',\n",
              " 'voices',\n",
              " 'your',\n",
              " 'nicely',\n",
              " 'bringing',\n",
              " 'glass',\n",
              " 'master',\n",
              " 'uncommon',\n",
              " 'losing',\n",
              " 'away',\n",
              " 'flurry',\n",
              " 'pleasant',\n",
              " 'rest',\n",
              " 'could',\n",
              " 'desperate',\n",
              " 'broken',\n",
              " 'rubbing',\n",
              " 'insult',\n",
              " 'screamed',\n",
              " 'neighbouring',\n",
              " 'remarking',\n",
              " 'pair',\n",
              " 'rule',\n",
              " 'helped',\n",
              " 'shall',\n",
              " 'fifth',\n",
              " 'sneezing',\n",
              " 'wants',\n",
              " 'hers',\n",
              " 'rabbit',\n",
              " 'use',\n",
              " 'Ah',\n",
              " 'pretty',\n",
              " 'mine',\n",
              " 'neighbour',\n",
              " 'grins',\n",
              " 'swallowing',\n",
              " 'without',\n",
              " 'bound',\n",
              " 'having',\n",
              " 'rippling',\n",
              " 'marked',\n",
              " 'curly',\n",
              " 'feathers',\n",
              " 'leaders',\n",
              " 'moving',\n",
              " 'trot',\n",
              " 'lost',\n",
              " 'Allow',\n",
              " 'different',\n",
              " 'sugar',\n",
              " 'shaking',\n",
              " 'will',\n",
              " 'give',\n",
              " 'Latitude',\n",
              " 'be',\n",
              " 'advantage',\n",
              " 'talking',\n",
              " 'pool',\n",
              " 'Alas',\n",
              " 'clever',\n",
              " 'particular',\n",
              " 'muttering',\n",
              " 'execution',\n",
              " 'modern',\n",
              " 'ancient',\n",
              " 'books',\n",
              " 'I',\n",
              " 'fifteen',\n",
              " 'something',\n",
              " 'arrow',\n",
              " 'hurriedly',\n",
              " 'mistake',\n",
              " 'lefthand',\n",
              " 'footsteps',\n",
              " 'Laughing',\n",
              " 'boxed',\n",
              " 'opened',\n",
              " 'maybe',\n",
              " 'lullaby',\n",
              " 'feet',\n",
              " 'As',\n",
              " 'washing',\n",
              " 'Run',\n",
              " 'entrance',\n",
              " 'myself',\n",
              " 'crimson',\n",
              " 'longer',\n",
              " 'Be',\n",
              " 'push',\n",
              " 'far',\n",
              " 'story',\n",
              " 'tulip',\n",
              " 'saying',\n",
              " 'hearts',\n",
              " 'A',\n",
              " 'Cat',\n",
              " 'only',\n",
              " 'Tortoise',\n",
              " 'wag',\n",
              " 'dainties',\n",
              " 'suppose',\n",
              " 'unrolled',\n",
              " 'constant',\n",
              " 'rises',\n",
              " 'Atheling',\n",
              " 'tarts',\n",
              " 'pence',\n",
              " 'housemaid',\n",
              " 'treat',\n",
              " 'maps',\n",
              " 'sneeze',\n",
              " 'mournfully',\n",
              " 'clamour',\n",
              " 'hear',\n",
              " 'Lizard',\n",
              " 'dodged',\n",
              " 'height',\n",
              " 'years',\n",
              " 'hate',\n",
              " 'mischief',\n",
              " 'cardboard',\n",
              " 'morning',\n",
              " 'concert',\n",
              " 'generally',\n",
              " 'uncomfortable',\n",
              " 'stretched',\n",
              " 'blow',\n",
              " 'yesterday',\n",
              " 'meat',\n",
              " 'rattle',\n",
              " 'shrill',\n",
              " 'Digging',\n",
              " 'twist',\n",
              " 'eye',\n",
              " 'saves',\n",
              " 'sweet',\n",
              " 'shape',\n",
              " 'down',\n",
              " 'says',\n",
              " 'questions',\n",
              " 'beautiful',\n",
              " 'bank',\n",
              " 'Writhing',\n",
              " 'note',\n",
              " 'cutting',\n",
              " 'girls',\n",
              " 'Indeed',\n",
              " 'lobsters',\n",
              " 'producing',\n",
              " 'sneezed',\n",
              " 'Esq',\n",
              " 'smoke',\n",
              " 'No',\n",
              " 'picture',\n",
              " 'goes',\n",
              " 'day',\n",
              " 'feel',\n",
              " 'skurried',\n",
              " 'guests',\n",
              " 'sleepy',\n",
              " 'And',\n",
              " 'skimming',\n",
              " 'furious',\n",
              " 'character',\n",
              " 'face',\n",
              " 'hurry',\n",
              " 'person',\n",
              " 'curtain',\n",
              " 'cheeks',\n",
              " 'drunk',\n",
              " 'timid',\n",
              " 'noise',\n",
              " 'diamonds',\n",
              " 'nearer',\n",
              " 'playing',\n",
              " 'cup',\n",
              " 'one',\n",
              " 'moral',\n",
              " 'coming',\n",
              " 'Hearthrug',\n",
              " 'p',\n",
              " 'audibly',\n",
              " 'lesson',\n",
              " 'Longitude',\n",
              " 'spite',\n",
              " 'wondering',\n",
              " 'doorway',\n",
              " 'We',\n",
              " 'Mind',\n",
              " 'Croquet',\n",
              " 'personal',\n",
              " 'roots',\n",
              " 'size',\n",
              " 'flat',\n",
              " 'offended',\n",
              " 'puzzled',\n",
              " 'fair',\n",
              " 'EDITION',\n",
              " 'break',\n",
              " 'dismay',\n",
              " 'tumbling',\n",
              " 'picked',\n",
              " 'has',\n",
              " 'muddle',\n",
              " 'upright',\n",
              " 'pinch',\n",
              " 'tight',\n",
              " 'conger',\n",
              " 'royal',\n",
              " 'paw',\n",
              " 'whistle',\n",
              " 'timidly',\n",
              " 'wrapping',\n",
              " 'crumbs',\n",
              " 'curving',\n",
              " 'mean',\n",
              " 'pattering',\n",
              " 'tidy',\n",
              " 'please',\n",
              " 'toast',\n",
              " 'children',\n",
              " 'taken',\n",
              " 'come',\n",
              " 'hit',\n",
              " 'kneel',\n",
              " 'abide',\n",
              " 'candle',\n",
              " 'side',\n",
              " 'executes',\n",
              " 'know',\n",
              " 'grunt',\n",
              " 'shoulder',\n",
              " 'hopeful',\n",
              " 'Pennyworth',\n",
              " 'yet',\n",
              " 'sister',\n",
              " 'Said',\n",
              " 'comes',\n",
              " 'presents',\n",
              " 'So',\n",
              " 'pretend',\n",
              " 'Would',\n",
              " 'door',\n",
              " 'est',\n",
              " 'choice',\n",
              " 'eggs',\n",
              " 'thank',\n",
              " 'appearance',\n",
              " 'largest',\n",
              " 'nose',\n",
              " 'mixed',\n",
              " 'sun',\n",
              " 'led',\n",
              " 'shut',\n",
              " 'confusing',\n",
              " 'slipped',\n",
              " 'meal',\n",
              " 'bleeds',\n",
              " 'like',\n",
              " 'country',\n",
              " 'rattling',\n",
              " 'rushed',\n",
              " 'cautiously',\n",
              " 'juror',\n",
              " 'alarmed',\n",
              " 'whatever',\n",
              " 'above',\n",
              " 'yelp',\n",
              " 'emphasis',\n",
              " 'incessantly',\n",
              " 'evidence',\n",
              " 'stood',\n",
              " 'Lewis',\n",
              " 'useful',\n",
              " 'cake',\n",
              " 'crash',\n",
              " 'trumpet',\n",
              " 'offend',\n",
              " 'trouble',\n",
              " 'daresay',\n",
              " 'Forty',\n",
              " 'making',\n",
              " 'curls',\n",
              " 'expecting',\n",
              " 'resting',\n",
              " 'music',\n",
              " 'invitation',\n",
              " 'or',\n",
              " 'Heads',\n",
              " 'Majesty',\n",
              " 'fall',\n",
              " 'Ada',\n",
              " 'concluded',\n",
              " 'died',\n",
              " 'a',\n",
              " 'smile',\n",
              " 'darkness',\n",
              " 'began',\n",
              " 'pinched',\n",
              " 'hedges',\n",
              " 'Once',\n",
              " 'very',\n",
              " 'speed',\n",
              " 'feeling',\n",
              " 'fire',\n",
              " 'taste',\n",
              " 'Nile',\n",
              " 'them',\n",
              " 'funny',\n",
              " 'spectacles',\n",
              " 'driest',\n",
              " 'dreaming',\n",
              " 'met',\n",
              " 'soldier',\n",
              " 'pegs',\n",
              " 'Very',\n",
              " 'dropped',\n",
              " 'their',\n",
              " 'shoulders',\n",
              " 'irons',\n",
              " 'slowly',\n",
              " 'nevertheless',\n",
              " 'caused',\n",
              " 'pleasanter',\n",
              " 'assembled',\n",
              " 'yelled',\n",
              " 'six',\n",
              " 'depends',\n",
              " 'extraordinary',\n",
              " 'label',\n",
              " 'why',\n",
              " 'ridiculous',\n",
              " 'crouched',\n",
              " 'cunning',\n",
              " 'fighting',\n",
              " 'muscular',\n",
              " 'goose',\n",
              " 'jumped',\n",
              " 'failure',\n",
              " 'sternly',\n",
              " 'thatched',\n",
              " 'For',\n",
              " 'when',\n",
              " 'RABBIT',\n",
              " 'tree',\n",
              " 'elegant',\n",
              " 'impossible',\n",
              " 'ceiling',\n",
              " 'trees',\n",
              " 'nursing',\n",
              " 'ever',\n",
              " 'pronounced',\n",
              " 'wings',\n",
              " 'spell',\n",
              " 'front',\n",
              " 'Foot',\n",
              " 'stays',\n",
              " 'closer',\n",
              " 'difficulties',\n",
              " 'feelings',\n",
              " 'Panther',\n",
              " 'angrily',\n",
              " 'chose',\n",
              " 'see',\n",
              " 'did',\n",
              " 'pine',\n",
              " 'subjects',\n",
              " 'been',\n",
              " 'nearly',\n",
              " 'Fainting',\n",
              " 'sadly',\n",
              " 'eyes',\n",
              " 'saw',\n",
              " 'blasts',\n",
              " 'swallowed',\n",
              " 'signify',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GfkThRpNUKL"
      },
      "source": [
        "Define a function that takes a word and lists the $n$ most similar words in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_h-7n50kia"
      },
      "source": [
        "def spacy_closest(tokens, new_vec, n=10):\n",
        "  # Your code here\n",
        "  similar_words = []\n",
        "  for c in sorted(tokens,key=lambda x: cosine(new_vec,nlp(x).vector),reverse=True)[:n]:\n",
        "    similar_words.append(c)\n",
        "  return similar_words\n",
        "  pass"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLEiz9UNjrO"
      },
      "source": [
        "Try to find words similar to some random words, e.g. $good$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_closest(tokens, nlp('coffee').vector)"
      ],
      "metadata": {
        "id": "dm0iK3jc8YqI",
        "outputId": "ebf75ddc-a817-41de-c66a-d3ddaa213197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d055a8687946>:5: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  cs = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kettle',\n",
              " 'milk',\n",
              " 'bottle',\n",
              " 'roast',\n",
              " 'soup',\n",
              " 'sugar',\n",
              " 'dinner',\n",
              " 'vegetable',\n",
              " 'apple',\n",
              " 'tastes']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1JL2VrF0ltD",
        "outputId": "f66d93fa-1df9-4ec8-c2d8-0470f2e5f73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spacy_closest(tokens, nlp('good').vector)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d055a8687946>:5: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  cs = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good',\n",
              " 'bad',\n",
              " 'better',\n",
              " 'wonderful',\n",
              " 'clever',\n",
              " 'really',\n",
              " 'pleasing',\n",
              " 'uncomfortable',\n",
              " 'certainly',\n",
              " 'little']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBZhjqSgNqNd"
      },
      "source": [
        "You can also get creative and search for combinations of words. For example, what is similar to $king - man + woman$?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKI4SrhMN-EV",
        "outputId": "acda2768-9c19-41af-ef66-bcd6d1097926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Your code here\n",
        "new_vec = nlp('king').vector - nlp('man').vector + nlp('woman').vector\n",
        "spacy_closest(tokens, new_vec)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d055a8687946>:5: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  cs = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Queen',\n",
              " 'usurpation',\n",
              " 'neighbouring',\n",
              " 'authority',\n",
              " 'ancient',\n",
              " 'instance',\n",
              " 'Fainting',\n",
              " 'familiarly',\n",
              " 'generally',\n",
              " 'particular']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpD73pj8OGGt"
      },
      "source": [
        "## **Sentence vectors**\n",
        "\n",
        "We can also construct a vector representation for the whole sentence. For example, we can define it as an *average* of the   vectors representing the words in it.\n",
        "\n",
        "Let's take a random sentence *My favorite food is strawberry ice cream* and construct its vector representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5xr_3MkEPeM"
      },
      "source": [
        "sent = nlp('My favorite food is strawberry ice cream.')\n",
        "\n",
        "# Your code here\n",
        "sentv = 0\n",
        "for word in sent:\n",
        "  sentv +=  word.vector\n",
        "sentv/=len(sent)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMf_OllyOvfX"
      },
      "source": [
        "Let's also extract sentences (as opposed to individual words) from our corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jazUz0WvDsa3",
        "outputId": "0aa5e477-16dd-4c4c-cf55-e09896542fee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sents = list(doc.sents)\n",
        "sents[:3]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ï»¿ï»¿*** START OF THE PROJECT GUTENBERG EBOOK,\n",
              " ALICE'S ADVENTURES IN\n",
              " WONDERLAND *,\n",
              " **\n",
              " [Illustration]\n",
              " \n",
              " \n",
              " \n",
              " \n",
              " Aliceâs Adventures in Wonderland\n",
              " \n",
              " by Lewis Carroll\n",
              " \n",
              " THE MILLENNIUM FULCRUM EDITION 3.0\n",
              " \n",
              " Contents\n",
              " \n",
              "  CHAPTER I.     Down the Rabbit-Hole\n",
              "  CHAPTER II.    ]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzDdce7xO7QZ"
      },
      "source": [
        "Define a function that takes a random sentence and lists $n$ most similar sentences from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7pQe8xD1x0"
      },
      "source": [
        "def spacy_closest_sent(sentences, input_vec, n=10):\n",
        "  # Your code here\n",
        "  return sorted(sentences,\n",
        "                  key = lambda x: cosine(np.mean([w.vector for w in x],axis=0),input_vec),\n",
        "                  reverse=True)[:n]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6m06T18PDQ8"
      },
      "source": [
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkDCEWWwEzIc",
        "outputId": "69df2809-36f1-4a33-d9e6-c7962b8ea9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for s in spacy_closest_sent(sents, sentv, n=10):\n",
        "  print(s)\n",
        "  print('\\n---')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This\r\n",
            "is the driest thing I know.\n",
            "\n",
            "---\n",
            "And oh, my poor hands, how is it\n",
            "\n",
            "---\n",
            "beautiful Soup!\r\n",
            "Soup of the evening, beautiful Soup!\r\n",
            "    Beauâootiful Sooâoop!\r\n",
            "    \n",
            "\n",
            "---\n",
            "Oh\r\n",
            "my fur and whiskers!\n",
            "\n",
            "---\n",
            "âI dare say youâre wondering why I donât put my arm round your waist,â\r\n",
            "the Duchess said after a pause: âthe reason is, that Iâm doubtful about\r\n",
            "the temper of your flamingo.\n",
            "\n",
            "---\n",
            "The Mouse did not\r\n",
            "answer, so Alice went on eagerly: âThere is such a nice little dog near\r\n",
            "our house I should like to show you!\n",
            "\n",
            "---\n",
            "And sheâs such a capital one for catching mice you\r\n",
            "canât think!\n",
            "\n",
            "---\n",
            "Soup\r\n",
            "does very well withoutâMaybe itâs always pepper that makes people\r\n",
            "hot-tempered,â she went on, very much pleased at having found out a new\r\n",
            "kind of rule, âand vinegar that makes them sourâand camomile that makes\r\n",
            "them bitterâandâand barley-sugar and such things that make children\r\n",
            "sweet-tempered.\n",
            "\n",
            "---\n",
            "she knows such a\r\n",
            "very little!\n",
            "\n",
            "---\n",
            "And she tried to fancy what the\r\n",
            "flame of a candle is like after the candle is blown out, for she could\r\n",
            "not remember ever having seen such a thing.\r\n",
            "\r\n",
            "\n",
            "\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d055a8687946>:5: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  cs = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VewB5XqkPLdx"
      },
      "source": [
        "## **References**\n",
        "\n",
        "This notebook is inspired by a [tutorial by Allison Parrish](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469)."
      ]
    }
  ]
}